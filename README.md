# mockGPT
The whole world is taken by storm with the launch of [ChatGPT](https://chat.openai.com/) by [open.ai](https://openai.com/).

While big Tech giants Google, Microsoft, Apple, Meta, ... are jumping into the space to make an AGI or LLM based products, this project is a small attempt to create a Transformer based LLM, like GPT from scratch.

This project is heavily inspired by Andrej Karpathy's series on [Neural Networks](https://www.youtube.com/playlist?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ), and the video [Let's build GPT](https://youtu.be/kCc8FmEb1nY)

Note: The chances of succeeding with this project is low in my first attempt, and even if I do, I believe that the model will turn out to be small, with limited training dataset. Hence there should't be any safety concerns as **Sam Altman** describes in **Lex Fridman Podcast #367**, in the section: Fear ([1:09:05](https://youtu.be/L_Guz73e6fw?t=4145))
